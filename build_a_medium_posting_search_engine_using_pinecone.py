# -*- coding: utf-8 -*-
"""Build a Medium Posting Search Engine using Pinecone

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13s0wQS93VdnHoWNGJx8S9-F5ncO3YvzI

# Build a Medium Posting Search Engine using Pinecone

 * Utilize Kaggle Data: https://www.kaggle.com/datasets/arnabchaki/medium-articles-dataset
 * Better Use GPU Runtime

### Load Data
"""

!pip3 install sentence-transformers

!pip3 install pinecone

"""## Download Medium article data"""

!wget https://s3-geospatial.s3.us-west-2.amazonaws.com/medium_data.csv

!wc -l medium_data.csv

"""## Preprocess Medium data and save it as a file"""

import pandas as pd

df = pd.read_csv("medium_data.csv") # excercise whole data set

df.head()

df.info()

"""### Data Cleanup"""

df['title'] = df['title'].astype(str).fillna('')
df['subtitle'] = df['subtitle'].astype(str).fillna('')

df['metadata'] = df.apply(lambda row: {'title': row['title'] + " " + row['subtitle']}, axis=1)

df.head()

"""### Prep for Upsert"""

from google.colab import userdata

# Use Colab Secrets
API_KEY = userdata.get('pinecone_key')

from pinecone import Pinecone

pc = Pinecone(api_key=API_KEY)

from pinecone import ServerlessSpec

# Spec for free tier plan
spec = ServerlessSpec(
    cloud="aws",
    region="us-east-1"
)

index_name = 'semantic-search-fast'

existing_indexes = [
    index_info["name"] for index_info in pc.list_indexes()
]

existing_indexes

import time

# If the following code runs more than once, you might get "The index already existed" error
# In that case, delete the index first: pc.delete_index(index_name)
try:
    pc.delete_index(index_name)
except Exception as e:
    print(e)

pc.create_index(
    index_name,
    dimension=384,  # dimensionality of minilm
    metric='dotproduct',
    spec=spec
)
# wait for index to be initialized
while not pc.describe_index(index_name).status['ready']:
    time.sleep(1)

from sentence_transformers import SentenceTransformer
import torch

"""## Generate sentence embeddings and ingest them into Pinecone

If you want to use "cuda", change the runtime to GPU
"""

# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu') # cuda or cpu

# .apply(lambda x: ...): This applies a function to each row in the 'metadata' column.
# model.encode(x["title"]): This uses a sentence embedding model to encode the text in the "title" field of x into a vector (embedding).
# .tolist(): Converts the embedding (a NumPy array) to a regular Python list.
# df['values'] = df['metadata'].map(
#    lambda x: (model.encode(x["title"])).tolist())
df['values'] = df['metadata'].apply(
    lambda x: model.encode(x['title']).tolist()) # python list, 6k rows 1 min

df.head()

# 'values', 'metadata', 'sparse_values', 'id'
df_upsert = df[['id', 'values', 'metadata']]

# df_upsert['id'] = df_upsert['id'].map(lambda x: str(x))
df_upsert['id'] = df_upsert['id'].astype(str)

df_upsert.head()

index = pc.Index(index_name)

index.upsert_from_dataframe(df_upsert) # 6k takes 1 min

"""### Query"""

xc = index.query(vector=(model.encode("what is ethics in AI")).tolist(), # python list
           top_k=10,
           include_metadata=True,
           include_values=True)   #

for result in xc['matches']:
    print(result['id'], result['score'], result['metadata'])

